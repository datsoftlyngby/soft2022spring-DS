{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Vectorisation of Text Data\n",
    "(not complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of converting or transforming a data set into a set of Vectors is called Vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter two sentences for the test\n",
    "sent1 = \"Data Science is the sexiest job of the 21st century.\"\n",
    "sent2 = \"Machine learning is the key for data science.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the sentences in words\n",
    "sent1 = sent1.split(\" \")\n",
    "sent2 = sent2.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the sets of words to remove duplications\n",
    "all= set(sent1).union(set(sent2))\n",
    "print(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus size\n",
    "len(all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and remember where each word appears.\n",
    "Start from two empty dictionaries, one for each sentence.\n",
    "Add the words that appear in the sentences, every time they repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict with the words are the keys and the numbers of their appearance as values\n",
    "dict1 = dict.fromkeys(all, 0) \n",
    "for word in sent1:\n",
    "    dict1[word]+=1\n",
    "dict1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2 = dict.fromkeys(all, 0)  \n",
    "for word in sent2:\n",
    "    dict2[word]+=1\n",
    "dict2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the dictionaires in a data frame\n",
    "df = pd.DataFrame([dict1, dict2])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity of Two Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dot product of two vectors, divide it by the magnitudes to find the cos(angle between them)\n",
    "# Use the result as a correlation coefficient \n",
    "from collections import Counter\n",
    "\n",
    "def cosine(vector1, vector2):\n",
    "     # calculate nominator as a dot product\n",
    "     intersect = set(vector1.keys()) & set(vector2.keys())\n",
    "     numerator = sum([vector1[x] * vector2[x] for x in intersect])\n",
    "    \n",
    "     # calculate the denominator \n",
    "     sum1 = sum([vector1[x] ** 2 for x in list(vector1.keys())])\n",
    "     sum2 = sum([vector2[x] ** 2 for x in list(vector2.keys())])\n",
    "    \n",
    "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "     if not denominator:\n",
    "         return 0.0\n",
    "     else:\n",
    "         return float(numerator)/denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the correlation\n",
    "corr = cosine(dict1, dict2)\n",
    "print(\"Similarity: \", corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of Each Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to compute the TD frequency of appearance of a word in documents\n",
    "def computeTF(dicto, doc):\n",
    "    tfDict = {}\n",
    "    corpus = len(doc) # number of all words\n",
    "    for word, wcount in dicto.items():\n",
    "        tfDict[word] = wcount/float(corpus) # calculate the proportion\n",
    "    return(tfDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function for both sets\n",
    "tf1 = computeTF(dict1, sent1)\n",
    "tf2 = computeTF(dict2, sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store into dataframe\n",
    "tf = pd.DataFrame([tf1, tf2])\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF -  inverse of the document frequency which measures the informativeness of term t\n",
    "#  lower occurance - higher importance of the word\n",
    "# idf(t) = N/df\n",
    "# to avoid div by zero: idf(t) = log(N/(df + 1))\n",
    "\n",
    "def computeIDF(docList):\n",
    "    idf = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idf = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for word, wcount in idf.items():\n",
    "        idf[word] = math.log10(N/(float(wcount) + 1))\n",
    "        \n",
    "    return(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputing our sentences in the log file\n",
    "idfs = computeIDF([dict1, dict2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate tf-idf as a measure for the importance of a word\n",
    "# tf-idf(t, d) = tf(t, d) * log(N/(df + 1))\n",
    "def computeTFIDF(tf, idfs):\n",
    "    tfidf = {}\n",
    "    for word, wcount in tf.items():\n",
    "        tfidf[word] = wcount*idfs[word]\n",
    "    return(tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running our two sentences through the IDF:\n",
    "idf1 = computeTFIDF(tf1, idfs)\n",
    "idf2 = computeTFIDF(tf2, idfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# store in a dataframe\n",
    "idf= pd.DataFrame([idf1, idf2])\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
